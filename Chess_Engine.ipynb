{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chess_Engine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamoN1nja/Chess-Engine/blob/main/Chess_Engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksuWXqAzyg2K"
      },
      "source": [
        "This notebook is trying to follow the advice from this website: https://towardsdatascience.com/creating-a-chess-ai-using-deep-learning-d5278ea7dcf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YRuxVSvtYr4"
      },
      "source": [
        "First: Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yO_Z3p0G7b5v"
      },
      "source": [
        "import os\n",
        "import chess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIxUMaoV7l1l"
      },
      "source": [
        "Second: Access GitHub Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfcMaauB4rbj",
        "outputId": "65b0741a-2a2e-4a66-e216-2815dba5b0f8"
      },
      "source": [
        "!git clone https://github.com/CamoN1nja/Chess-Engine.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Chess-Engine' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKX04JUe7TNu"
      },
      "source": [
        "Third: Access Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rp5aq50k7gh0"
      },
      "source": [
        "df = pd.read_csv('/content/Chess-Engine/games1000.csv')\n",
        "data = df['moves'].tolist()\n",
        "split_data = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvwarc_xzlZl"
      },
      "source": [
        "Fourth: One-Hot Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_zeDesPzz-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e9d984-a7f2-4bf9-abaf-3e3f08ee19db"
      },
      "source": [
        "chess_dict = {\n",
        "    'p' : [1,0,0,0,0,0,0,0,0,0,0,0],\n",
        "    'P' : [0,0,0,0,0,0,1,0,0,0,0,0],\n",
        "    'n' : [0,1,0,0,0,0,0,0,0,0,0,0],\n",
        "    'N' : [0,0,0,0,0,0,0,1,0,0,0,0],\n",
        "    'b' : [0,0,1,0,0,0,0,0,0,0,0,0],\n",
        "    'B' : [0,0,0,0,0,0,0,0,1,0,0,0],\n",
        "    'r' : [0,0,0,1,0,0,0,0,0,0,0,0],\n",
        "    'R' : [0,0,0,0,0,0,0,0,0,1,0,0],\n",
        "    'q' : [0,0,0,0,1,0,0,0,0,0,0,0],\n",
        "    'Q' : [0,0,0,0,0,0,0,0,0,0,1,0],\n",
        "    'k' : [0,0,0,0,0,1,0,0,0,0,0,0],\n",
        "    'K' : [0,0,0,0,0,0,0,0,0,0,0,1],\n",
        "    '.' : [0,0,0,0,0,0,0,0,0,0,0,0],\n",
        "}\n",
        "alpha_dict = {\n",
        "    'a' : [0,0,0,0,0,0,0],\n",
        "    'b' : [1,0,0,0,0,0,0],\n",
        "    'c' : [0,1,0,0,0,0,0],\n",
        "    'd' : [0,0,1,0,0,0,0],\n",
        "    'e' : [0,0,0,1,0,0,0],\n",
        "    'f' : [0,0,0,0,1,0,0],\n",
        "    'g' : [0,0,0,0,0,1,0],\n",
        "    'h' : [0,0,0,0,0,0,1],\n",
        "}\n",
        "number_dict = {\n",
        "    1 : [0,0,0,0,0,0,0],\n",
        "    2 : [1,0,0,0,0,0,0],\n",
        "    3 : [0,1,0,0,0,0,0],\n",
        "    4 : [0,0,1,0,0,0,0],\n",
        "    5 : [0,0,0,1,0,0,0],\n",
        "    6 : [0,0,0,0,1,0,0],\n",
        "    7 : [0,0,0,0,0,1,0],\n",
        "    8 : [0,0,0,0,0,0,1],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r n b q k b n r\n",
            "p p p p p p p p\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            ". . . . . . . .\n",
            "P P P P P P P P\n",
            "R N B Q K B N R\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydPOj9Akz46O"
      },
      "source": [
        "Fifth: Preliminary Functions to Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9YkELf90HBe"
      },
      "source": [
        "def make_matrix(board): \n",
        "    pgn = board.epd()\n",
        "    foo = []  \n",
        "    pieces = pgn.split(\" \", 1)[0]\n",
        "    rows = pieces.split(\"/\")\n",
        "    for row in rows:\n",
        "        foo2 = []  \n",
        "        for thing in row:\n",
        "            if thing.isdigit():\n",
        "                for i in range(0, int(thing)):\n",
        "                    foo2.append('.')\n",
        "            else:\n",
        "                foo2.append(thing)\n",
        "        foo.append(foo2)\n",
        "    return foo\n",
        "def translate(matrix,chess_dict):\n",
        "    rows = []\n",
        "    for row in matrix:\n",
        "        terms = []\n",
        "        for term in row:\n",
        "            terms.append(chess_dict[term])\n",
        "        rows.append(terms)\n",
        "    return rows"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXh0tSKo0gFo"
      },
      "source": [
        "Sixth: Create Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5z-YD1030KFV"
      },
      "source": [
        "for point in data:\n",
        "    split_data.append(point)\n",
        "    \n",
        "data = []\n",
        "for i in range(0, 999):\n",
        "    game = split_data[i]\n",
        "    board = chess.Board()\n",
        "    moves=game.split()\n",
        "    for move in moves:\n",
        "        board_ready = board.copy()\n",
        "        data.append(board.copy())\n",
        "        board.push_san(move)\n",
        "trans_data = []\n",
        "for board in data:\n",
        "    matrix = make_matrix(board)\n",
        "    trans = translate(matrix,chess_dict)\n",
        "    trans_data.append(trans)\n",
        "pieces = []\n",
        "alphas = []\n",
        "numbers = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHe_hVCM2b6I"
      },
      "source": [
        "Seventh: Transform Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3Sd_t7G0mhL"
      },
      "source": [
        "true_data = split_data\n",
        "for i in range(len(true_data)):\n",
        "    try:\n",
        "        term = split_data[i]\n",
        "        original = term[:]\n",
        "        term = term.replace('x','')\n",
        "        term = term.replace('#','')\n",
        "        term = term.replace('+','')\n",
        "        if len(term) == 2:\n",
        "            piece = 'p' \n",
        "        else:\n",
        "            piece = term[0]\n",
        "        alpha = term[-2]\n",
        "        number = term[-1]\n",
        "        pieces.append(chess_dict[piece])\n",
        "        alphas.append(alpha_dict[alpha])\n",
        "        numbers.append(number_dict[int(number)])\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K62JjBKt6QFB"
      },
      "source": [
        "Eighth: Creating the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC1m5Mjj6OV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c358246-63ff-4ba4-af21-6bb56e9240f5"
      },
      "source": [
        "board_inputs = keras.Input(shape=(8, 8, 12))\n",
        "conv1= layers.Conv2D(10, 3, activation='relu')\n",
        "conv2 = layers.Conv2D(10, 3, activation='relu')\n",
        "pooling1 = layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None,)\n",
        "pooling2 = layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None,)\n",
        "flatten = keras.layers.Flatten(data_format=None)\n",
        "x = conv1(board_inputs)\n",
        "x = pooling1(x)\n",
        "x = conv2(x)\n",
        "x = flatten(x)\n",
        "piece_output = layers.Dense(12,name = 'piece')(x)\n",
        "print(board_inputs)\n",
        "model_pieces = keras.Model(inputs=board_inputs, outputs=piece_output, name=\"chess_ai_v3\")\n",
        "earlystop = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=250, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
        "model_pieces.compile(\n",
        "    loss=keras.losses.mse,\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=None,\n",
        ")\n",
        "model_pieces.fit(trans_data[:len(pieces)],pieces[:len(pieces)],batch_size=64, epochs=100,callbacks = [earlystop])\n",
        "board_inputs = keras.Input(shape=(8, 8, 12))\n",
        "conv1= layers.Conv2D(10, 3, activation='relu')\n",
        "conv2 = layers.Conv2D(10, 3, activation='relu')\n",
        "pooling1 = layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None,)\n",
        "pooling2 = layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None,)\n",
        "flatten = keras.layers.Flatten(data_format=None)\n",
        "x = conv1(board_inputs)\n",
        "x = pooling1(x)\n",
        "x = conv2(x)\n",
        "x = flatten(x)\n",
        "alpha_output = layers.Dense(7,name = 'alpha')(x)\n",
        "model_alpha = keras.Model(inputs=board_inputs, outputs=alpha_output, name=\"chess_ai_v3\")\n",
        "earlystop = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=250, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
        "model_alpha.compile(\n",
        "    loss=keras.losses.mse,\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=None,\n",
        ")\n",
        "model_alpha.fit(trans_data[:len(alphas)],alphas[:len(alphas)],batch_size=64, epochs=100,callbacks = [earlystop])\n",
        "board_inputs = keras.Input(shape=(8, 8, 12))\n",
        "conv1= layers.Conv2D(10, 3, activation='relu')\n",
        "conv2 = layers.Conv2D(10, 3, activation='relu')\n",
        "pooling1 = layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None,)\n",
        "pooling2 = layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"valid\", data_format=None,)\n",
        "flatten = keras.layers.Flatten(data_format=None)\n",
        "x = conv1(board_inputs)\n",
        "x = pooling1(x)\n",
        "x = conv2(x)\n",
        "x = flatten(x)\n",
        "numbers_output = layers.Dense(7,name = 'number')(x)\n",
        "model_number = keras.Model(inputs=board_inputs, outputs=numbers_output, name=\"chess_ai_v3\")\n",
        "earlystop = keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=250, verbose=0, mode='auto', baseline=None, restore_best_weights=True)\n",
        "model_number.compile(\n",
        "    loss=keras.losses.mse,\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=None,\n",
        ")\n",
        "model_number.fit(trans_data[:len(numbers)],numbers[:len(numbers)],batch_size=64, epochs=100,callbacks = [earlystop])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 12), dtype=tf.float32, name='input_6'), name='input_6', description=\"created by layer 'input_6'\")\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0883\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0783\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0715\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0670\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0639\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0621\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0605\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0588\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0574\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0559\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0546\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0536\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0524\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0513\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0503\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0493\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0484\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0475\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0467\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0459\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0450\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0441\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0434\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0426\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0419\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0412\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0405\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0399\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0394\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0389\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0384\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0379\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0373\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0368\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0364\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0362\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0359\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0355\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0351\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0347\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0343\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0340\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0337\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0333\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0329\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0326\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0323\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0322\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0320\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0316\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0313\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0311\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0308\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0306\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0304\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0302\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0300\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0298\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0296\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0294\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0294\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0293\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0291\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0289\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0287\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0286\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0285\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0283\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0282\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0280\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0279\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0278\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0276\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0275\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0274\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0273\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0271\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0270\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0269\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0268\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0267\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0267\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0266\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0265\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0265\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0264\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0264\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0263\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0262\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0261\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0259\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0257\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0256\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0257\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0256\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0254\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0253\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0253\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0252\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0252\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1749\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1616\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1526\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1464\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1419\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1386\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1362\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1343\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1329\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1316\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1307\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1299\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1291\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1286\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1281\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1276\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1271\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1266\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1261\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1255\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1249\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1244\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1239\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1235\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1232\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1228\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1223\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1219\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1217\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1214\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1211\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1209\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1205\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1201\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1197\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1192\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1188\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1184\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1180\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1177\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1173\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1169\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1166\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1163\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1160\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1158\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1156\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1156\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1155\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1153\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1149\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1145\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1141\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1137\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1133\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1132\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1130\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1128\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1126\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1125\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1122\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1120\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1118\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1116\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1114\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1112\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1110\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1108\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1105\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1103\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1101\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1099\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1096\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1095\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1093\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1092\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1090\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1090\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1089\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1088\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1086\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1084\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1082\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1080\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1078\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1076\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1074\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.1071\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1070\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1069\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1068\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1066\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1064\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1065\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1067\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1067\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1065\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1062\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1061\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1059\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.2078\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1804\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1602\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1457\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1359\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1299\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1262\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1239\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1222\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1209\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1200\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1192\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1183\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1176\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1169\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1165\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1161\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1159\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1157\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1154\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1152\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1150\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1147\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1145\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1142\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1139\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1137\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1134\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1133\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1133\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1131\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1127\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1123\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1119\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1117\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1115\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1113\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1112\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1110\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1109\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1108\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1106\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1103\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1100\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1099\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1097\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1095\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1095\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1096\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1096\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1095\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1094\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1092\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1092\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1094\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1097\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1097\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1094\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1090\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1085\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1080\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1076\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1074\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1072\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1072\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1074\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1075\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1075\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1072\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1069\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1066\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1063\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1063\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1062\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1061\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1059\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1058\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.1059\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1059\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1059\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1061\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1064\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1063\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1059\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1053\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1049\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1049\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1049\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1047\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.1045\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1044\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1043\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1044\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1044\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.1042\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1040\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1037\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1035\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1034\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1033\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7cb92afcd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O_cXsyK6jq6"
      },
      "source": [
        "Ninth: Making Predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXr5HV6B6oS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1854ed7c-d4f7-49a7-c255-1d64e1df79ac"
      },
      "source": [
        "new_chess_dict = {}\n",
        "new_alpha_dict = {}\n",
        "new_number_dict = {}\n",
        "for term in chess_dict:\n",
        "    definition = tuple(chess_dict[term])\n",
        "    new_chess_dict[definition] = term\n",
        "    new_chess_dict[term] = definition\n",
        "    \n",
        "for term in alpha_dict:\n",
        "    definition = tuple(alpha_dict[term])\n",
        "    new_alpha_dict[definition] = term\n",
        "    new_alpha_dict[term] = definition\n",
        "    \n",
        "for term in number_dict:\n",
        "    definition = tuple(number_dict[term])\n",
        "    new_number_dict[definition] = term\n",
        "    new_number_dict[term] = definition\n",
        "data = np.reshape(trans_data[0],(1,8,8,12))\n",
        "pred = model_pieces.predict(data)\n",
        "def translate_pred(pred):\n",
        "    translation = np.zeros(pred.shape)\n",
        "    index = pred[0].tolist().index(max(pred[0]))\n",
        "    translation[0][index] = 1\n",
        "    return translation[0]\n",
        "piece = translate_pred(model_pieces.predict(data))\n",
        "alpha = translate_pred(model_alpha.predict(data))\n",
        "number = translate_pred(model_alpha.predict(data))\n",
        "piece_pred = new_chess_dict[tuple(piece)]\n",
        "alpha_pred = new_alpha_dict[tuple(alpha)]\n",
        "number_pred = new_number_dict[tuple(number)]\n",
        "move =str(piece_pred)+str(alpha_pred)+str(number_pred)\n",
        "print(move)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[0 0 0 1 0 0 0 0 0 0 0 0]\n",
            "   [0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "   [0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "   [0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 1 0 0 0 0 0 0 0 0]]\n",
            "\n",
            "  [[1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [1 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [1 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "\n",
            "  [[0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "\n",
            "  [[0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "\n",
            "  [[0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "\n",
            "  [[0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "\n",
            "  [[0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 1 0 0 0 0 0]\n",
            "   [0 0 0 0 0 0 1 0 0 0 0 0]]\n",
            "\n",
            "  [[0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "   [0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "   [0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "   [0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "   [0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "   [0 0 0 0 0 0 0 0 0 1 0 0]]]]\n",
            ". . k r . . . .\n",
            "p p p . p . . p\n",
            ". . . . N . p .\n",
            ". . . . . p . .\n",
            ". . . . . . . .\n",
            "P P . . . . P .\n",
            ". B P q K P . P\n",
            "R . . . . B R .\n",
            "Ng7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtlmIS2CufI9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}